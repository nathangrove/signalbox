import os
import re
import argparse
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.model_selection import train_test_split
from sklearn.calibration import CalibratedClassifierCV
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report
import joblib

URL_RE = re.compile(r'https?://\S+|\bwww\.\S+', re.I)

def load_from_db(conn_str, table='emails'):
    from sqlalchemy import create_engine, text
    eng = create_engine(conn_str, future=True)
    # Join messages with ai_metadata (version=1) to obtain labels generated by existing LLM
    q = text(
        "SELECT m.id as id, m.subject as subject, m.raw as raw, am.labels as labels "
        "FROM messages m JOIN ai_metadata am ON am.message_id = m.id AND am.version = 1 "
        "WHERE am.labels IS NOT NULL"
    )
    df = pd.read_sql(q, eng)
    return df

def load_from_csv(path):
    return pd.read_csv(path)

def load_data(csv_path=None, db_url=None):
    if db_url:
        df = load_from_db(db_url)
    else:
        df = load_from_csv(csv_path)
    # normalize
    df['subject'] = df.get('subject', '').fillna('').astype(str)

    # if 'raw' column present (bytea), parse to extract plain text
    def parse_raw_to_text(raw_val: any) -> str:
        try:
            if raw_val is None:
                return ''
            # raw_val may be memoryview/bytes; convert to bytes
            raw_bytes = raw_val if isinstance(raw_val, (bytes, bytearray)) else bytes(raw_val)
            from email import message_from_bytes
            from html import unescape
            import re

            msg = message_from_bytes(raw_bytes)
            parts = []
            if msg.is_multipart():
                for part in msg.walk():
                    ctype = part.get_content_type()
                    disp = str(part.get('Content-Disposition') or '')
                    if ctype == 'text/plain' and 'attachment' not in disp:
                        try:
                            parts.append(part.get_payload(decode=True).decode(part.get_content_charset() or 'utf-8', errors='replace'))
                        except Exception:
                            pass
                if parts:
                    return '\n'.join(parts)
                # fallback to first text/html
                for part in msg.walk():
                    ctype = part.get_content_type()
                    if ctype == 'text/html':
                        try:
                            html = part.get_payload(decode=True).decode(part.get_content_charset() or 'utf-8', errors='replace')
                            # very small html->text fallback
                            text = re.sub('<[^<]+?>', '', html)
                            return unescape(text)
                        except Exception:
                            pass
                return ''
            else:
                ctype = msg.get_content_type()
                if ctype == 'text/plain':
                    return msg.get_payload(decode=True).decode(msg.get_content_charset() or 'utf-8', errors='replace')
                if ctype == 'text/html':
                    html = msg.get_payload(decode=True).decode(msg.get_content_charset() or 'utf-8', errors='replace')
                    text = re.sub('<[^<]+?>', '', html)
                    return unescape(text)
                return ''
        except Exception:
            return ''

    if 'raw' in df.columns:
        df['body'] = df['raw'].map(parse_raw_to_text)
    else:
        df['body'] = df.get('body', '').fillna('').astype(str)

    df['text'] = (df['subject'] + '\n\n' + df['body']).map(lambda s: s.strip())

    # extract labels if available
    if 'labels' in df.columns:
        import json
        def extract_label_fields(x):
            try:
                if x is None:
                    return (None, None)
                if isinstance(x, str):
                    j = json.loads(x)
                else:
                    j = x
                category = j.get('category') if isinstance(j, dict) else None
                spam = j.get('spam') if isinstance(j, dict) else None
                return (category, bool(spam) if spam is not None else None)
            except Exception:
                return (None, None)
        labs = df['labels'].map(extract_label_fields)
        df['category'] = labs.map(lambda t: t[0])
        df['is_spam'] = labs.map(lambda t: t[1])
    return df

def meta_features(df):
    subj_len = df['subject'].map(len).values.reshape(-1,1)
    body_len = df['body'].map(len).values.reshape(-1,1)
    url_count = df['body'].map(lambda t: len(URL_RE.findall(t))).values.reshape(-1,1)
    has_html = df['body'].map(lambda t: int(bool(re.search(r'<\/?[a-z][\s\S]*>', t, re.I)))).values.reshape(-1,1)
    return np.hstack([subj_len, body_len, url_count, has_html])

def build_embeddings(sent_model, texts, batch_size=64):
    return sent_model.encode(texts.tolist(), show_progress_bar=True, batch_size=batch_size, convert_to_numpy=True)

def train_and_save(csv_path, db_url, out_path, emb_model_name='all-MiniLM-L6-v2', test_size=0.15, random_state=42):
    df = load_data(csv_path=csv_path, db_url=db_url)
    if df.empty:
        raise SystemExit("No training rows found")
    X_meta = meta_features(df)
    sent = SentenceTransformer(emb_model_name)
    X_emb = build_embeddings(sent, df['text'])
    X = np.hstack([X_emb, X_meta])

    # Spam model
    df['is_spam'] = df.get('is_spam', pd.Series(0, index=df.index)).fillna(0)
    y_spam = df['is_spam'].astype(int).values
    stratify_val = y_spam if len(set(y_spam)) > 1 else None
    X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X, y_spam, test_size=test_size, stratify=stratify_val, random_state=random_state)
    # Use XGBoost as base and calibrate spam probabilities (Platt / sigmoid)
    base_spam = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1)
    # Use sigmoid (Platt scaling) calibration with 3-fold CV for stability
    try:
        spam_clf = CalibratedClassifierCV(base_spam, cv=3, method='sigmoid')
        spam_clf.fit(X_train_s, y_train_s)
        y_prob = spam_clf.predict_proba(X_test_s)[:, 1]
        y_pred = spam_clf.predict(X_test_s)
    except Exception:
        # Fallback: fit base XGBoost without calibration
        base_spam.fit(X_train_s, y_train_s)
        spam_clf = base_spam
        y_prob = base_spam.predict_proba(X_test_s)[:, 1]
        y_pred = base_spam.predict(X_test_s)
    print("Spam metrics:", "acc", accuracy_score(y_test_s, y_pred), "roc_auc", roc_auc_score(y_test_s, y_prob) if len(set(y_test_s))>1 else None, "f1", f1_score(y_test_s, y_pred, zero_division=0))

    # Category model
    df['category'] = df.get('category', pd.Series('unknown', index=df.index)).fillna('unknown').astype(str)
    categories = sorted(df['category'].unique())
    # map categories to integer codes
    y_cat = df['category'].astype(pd.CategoricalDtype(categories=categories)).cat.codes.values
    # determine if stratified split is possible
    from collections import Counter
    cat_counts = Counter(y_cat)
    min_count = min(cat_counts.values()) if cat_counts else 0
    stratify_cat = y_cat if (len(categories) > 1 and min_count >= 2) else None
    X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_cat, test_size=test_size, stratify=stratify_cat, random_state=random_state)

    # Choose calibration strategy based on class sample sizes
    # Use XGBoost multi-class classifier
    if len(categories) > 1:
        cat_clf = XGBClassifier(objective='multi:softprob', num_class=len(categories), use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1)
    else:
        cat_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1)
    cat_clf.fit(X_train_c, y_train_c)
    y_pred_c = cat_clf.predict(X_test_c)
    print("Category report:")
    # classification_report requires target_names length to match labels present in y_test
    present = sorted(list(set(y_test_c)))
    names = [categories[i] for i in present]
    print(classification_report(y_test_c, y_pred_c, labels=present, target_names=names, zero_division=0))

    # ensure we store a classifier object for categories (calibrated or base)
    stored_cat_clf = cat_clf if cat_clf is not None else cat_base
    artifact = {
        'emb_model_name': emb_model_name,
        'categories': categories,
        'spam_clf': spam_clf,
        'category_clf': stored_cat_clf,
    }
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    joblib.dump(artifact, out_path)
    print("Saved model to", out_path)

if __name__ == '__main__':
    p = argparse.ArgumentParser()
    p.add_argument('--csv', default='data/emails.csv')
    p.add_argument('--out', default='models/email_models.joblib')
    p.add_argument('--emb', default='all-MiniLM-L6-v2')
    p.add_argument('--db', default=os.environ.get('DATABASE_URL'))
    args = p.parse_args()
    train_and_save(args.csv, args.db, args.out, emb_model_name=args.emb)
